import os
import sys
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.data.datasets import register_coco_instances
from detectron2.data import DatasetCatalog

# Mask2Former ëª¨ë“ˆ ë¡œë“œ
sys.path.insert(0, r"C:\scan_eat\Mask2Former")
try:
    from mask2former import add_maskformer2_config
except ImportError:
    print("âŒ Mask2Former í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ê²€ì¦ ë°ì´í„°ì…‹ ê²½ë¡œ (38ì¥)
VAL_JSON = r"C:\scan_eat\data\valid\_annotations.coco_final.json"
VAL_IMG = r"C:\scan_eat\data\valid\images"

def main():
    # ë°ì´í„°ì…‹ ë“±ë¡
    if "scaneat_val" not in DatasetCatalog.list():
        register_coco_instances("scaneat_val", {}, VAL_JSON, VAL_IMG)

    cfg = get_cfg()
    add_maskformer2_config(cfg)
    cfg.set_new_allowed(True)
    
    # ì„¤ì • íŒŒì¼ ë° ì™„ì„±ëœ ëª¨ë¸(ë‡Œ) ë¡œë“œ
    config_path = r"C:\scan_eat\Mask2Former\configs\coco\instance-segmentation\swin\maskformer2_swin_tiny_bs16_50ep.yaml"
    cfg.merge_from_file(config_path)
    
    # 2. ì˜¤ëŠ˜ í•™ìŠµ ì™„ë£Œëœ 'Phase 2' ëª¨ë¸ ë¡œë“œ
    cfg.MODEL.WEIGHTS = r"C:\scan_eat\output_unfreeze_backbone\model_final.pth"
    
    # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ê°•ì œ ë³´ì • ì„¸íŒ…
    cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 44
    cfg.MODEL.MASK_FORMER.NUM_CLASSES = 44
    cfg.INPUT.MIN_SIZE_TEST = 512
    cfg.INPUT.MAX_SIZE_TEST = 512
    cfg.MODEL.SEM_SEG_HEAD.CONVS_DIM = 256
    cfg.MODEL.SEM_SEG_HEAD.MASK_DIM = 256
    cfg.MODEL.SEM_SEG_HEAD.TRANSFORMER_ENC_LAYERS = 6
    cfg.MODEL.SEM_SEG_HEAD.IN_FEATURES = ["res2", "res3", "res4", "res5"]
    cfg.MODEL.MASK_ON = True
    cfg.INPUT.MASK_FORMAT = "bitmask"

    print("ğŸ¤– í‰ê°€ë¥¼ ìœ„í•´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    predictor = DefaultPredictor(cfg)
    
    # COCO í‰ê°€ê¸°(Evaluator) ìƒì„±
    evaluator = COCOEvaluator("scaneat_val", output_dir="./output")
    val_loader = build_detection_test_loader(cfg, "scaneat_val")
    
    print("\nğŸ“Š ê²€ì¦ ë°ì´í„°(valid)ë¡œ ì‹œí—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤! (mAP ì¶”ì¶œ ì¤‘...)\n")
    # í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
    val_results = inference_on_dataset(predictor.model, val_loader, evaluator)
    
    print("\n" + "="*50)
    print("ğŸ† ìµœì¢… ì„±ì í‘œ ")
    print("="*50)
    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì˜ˆì˜ê²Œ ì¶œë ¥
    for task, metrics in val_results.items():
        print(f"[{task}]")
        for metric, score in metrics.items():
            print(f" - {metric}: {score:.3f}")

if __name__ == "__main__":
    main()