# 🍕 SCAN Eat - Mask2Former Segmentation Pipeline (BJ's Workspace)

> **"박스(BBox)가 아닌 픽셀(Pixel)을 딴다!"** > SCAN Eat 프로젝트의 정밀한 음식 영역 추출을 위한 Mask2Former 파이프라인 구축 브랜치입니다.

---

## 🏗️ 1. 모델 아키텍처 (Model Architecture)

- **Task**: Instance Segmentation (음식 개별 객체 분할)
- **Head**: Mask2Former - 쿼리 기반 픽셀 분할 (COCO 데이터셋 사전 학습 모델 적용)
- **Backbone**: Swin-Transformer (Tiny) - 사전 학습된 시각 지능 엔진
- **Framework**: Detectron2 (Windows용 커스텀 빌드)

## 📊 2. 데이터셋 (Dataset)

- **도메인**: 한식 위주의 음식 이미지 (총 44개 클래스)
- **Train**: 620장 / **Valid**: 38장
- **포맷**: COCO format JSON (`_annotations.coco_final.json`)
- **최적화**: 윈도우 환경 메모리 누수 방지를 위한 `NUM_WORKERS = 0` 설정

## 💡 3. 핵심 구현 및 트러블슈팅

- **베테랑 모델(Pre-trained) 지식 이식**:
  인코더(Swin)만 학습된 상태에서 디코더(Mask2Former Head)까지 COCO 데이터로 학습된 전체 가중치를 로드하여 '백지상태'의 헤드 성능 문제를 근본적으로 해결함.
- **네트워크 보안 및 403 Forbidden 해결**:
  서버 측 직접 다운로드 차단 문제를 해결하기 위해 GitHub Model Zoo에서 가중치 파일(`86143f` 버전)을 수동 확보 후 로컬 경로 연결.
- **GitHub 인증 복구**:
  보안 정책 변경으로 인한 Push 실패를 PAT(Personal Access Token) 발급 및 자격 증명 업데이트를 통해 해결.

---

## 📅 작업 일지 (Dev Log)

### 📍 2026-02-23 ~ 2026-02-25 (환경 구축 및 1차 PoC)

- Detectron2 및 Mask2Former 로컬 설치.
- 1차 학습 진행 (10,000 iter) 결과 Segm mAP50 **38.6%** 달성.

### 📍 2026-02-26 (전략 최적화)

- 하이퍼파라미터 미세 조정: `Base LR` 0.00005 하향, `Weight Decay` 0.05 적용.
- 데이터 증강(RandomFlip, Multi-scale) 적용 완료.

### 📍 2026-02-27 (2차 파인튜닝 및 베테랑 모델 이식) ✅

- **모델 보완**: COCO 데이터셋으로 '칼질 실력'을 쌓은 베테랑 헤드 가중치 이식 성공.
- **성능 분석 (Valid 38장)**:
  - **종합 성적**: Segm AP50 **31.865%** 기록 (수치보다 정교한 경계선 추출에 집중).
  - **주요 성과**: 특정 음식군에서 높은 정확도 확보.
    - 간장게장 (GanjangCrab): **85.155%**
    - 진미채볶음 (SpicyDriedSquidBokkeum): **80.000%**
    - 닭갈비 (Dakgalbi): **70.957%**
  - **특이사항**: BBox mAP 0은 모델 구조적 특징임을 재확인, 검증 셋 부재 클래스는 `nan` 처리됨.

### 📍 2026-02-28 (파인튜닝 전략 심화 및 모델 적응성 분석) 🚀

- **실험 1: 백본 동결(Backbone Freeze) 파인튜닝**
  - **전략**: Swin-T 백본을 고정하고 Mask2Former Head(쿼리 및 디코더)만 학습시켜 소규모 데이터셋에서의 안정성 테스트.
  - **결과**: Segm AP50 **24.0%** 기록.
  - **인사이트**: 일반 객체(COCO)와 한국 음식 간의 시각적 격차(Domain Gap)가 커서, 백본을 고정할 경우 한식 특유의 질감과 형태를 포착하는 데 한계가 있음을 확인.

- **실험 2: 점진적 전체 해제 학습 (Two-stage Unfreezing)**
  - **전략**: 실험 1에서 학습된 모델을 기반으로 모든 동결을 해제하고, 낮은 학습률(`Base LR=0.00005`)로 전체 파라미터 미세 조정.
  - **결과**: Segm AP50 **29.1%** 달성 (동결 모델 대비 **+5.1%p** 향상).
  - **인사이트**: 백본의 빗장을 풀자마자 **간장게장(66.3%)**, **진미채(80.0%)** 등 특정 도메인에 대한 적응력이 즉각적으로 상승함.

- **📊 Mask2Former 최종 기술 분석 요약**
  - **최고 성능 기록**: 본 프로젝트 초기, 어떠한 제약 없이 전체 레이어를 학습시켰을 때 달성한 **38.6%**가 가장 높은 수치임을 재확인.
  - **데이터 효율성**: Mask2Former는 픽셀 정밀도가 높으나, 현재의 '스몰 데이터(620장)' 환경에서는 모델에 인위적인 제약(동결 등)을 주기보다 **전 영역을 유연하게 학습시키는 'Full Fine-tuning' 전략**이 가장 효과적임을 수치로 입증.
  - **결론**: 데이터가 적은 환경에서는 사전 학습된 지능을 보존하는 것보다, 모델의 전 가중치를 도메인 특화 특징(Texture) 학습에 동원하는 것이 유리함. 향후 데이터 확충 시 성능 역전 가능성 확인.
